{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.decomposition import TruncatedSVD\n",
    "#import online_nmf\n",
    "import copia_nmf\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "def SGD(data,R_df,info,n_factors,n_epochs):\n",
    "    import numpy as np\n",
    "    '''Learn the vectors p_u and q_i with SGD.\n",
    "       data is a dataset containing all ratings + some useful info (e.g. number\n",
    "       of items/users).\n",
    "    '''\n",
    "\n",
    "    # n_factors = 10  # number of factors\n",
    "    alpha = .01  # learning rate\n",
    "    # n_epochs = 50  # number of iteration of the SGD procedure\n",
    "\n",
    "    users = [ t[0] for t in info]\n",
    "    users = list(np.unique(np.asarray(users)))\n",
    "    movies = [ t[1] for t in info ]\n",
    "    movies = list(np.unique(np.asarray(movies)))\n",
    "    \n",
    "    #print (np.unique(users))\n",
    "    #print (np.unique(movies))\n",
    "    #return 0,0\n",
    "    n_users = len(np.unique(np.asarray(users)))#R_df.shape[0]\n",
    "    n_items = len(np.unique(np.asarray(movies)))#R_df.shape[1]\n",
    "\n",
    "    # Randomly initialize the user and item factors.\n",
    "    p = np.random.normal(0, .1, (n_users, n_factors))\n",
    "    q = np.random.normal(0, .1, (n_items, n_factors))\n",
    "\n",
    "    # Optimization procedure\n",
    "    for _ in range(n_epochs):\n",
    "        for u,i,r in info:\n",
    "            u_idx = users.index(u)\n",
    "            i_idx = movies.index(i)\n",
    "            if u_idx > n_users:\n",
    "                print(\"user out of bounds\",u_idx)\n",
    "                print(u,i,r)\n",
    "                return 0,0\n",
    "            if i_idx > n_items:\n",
    "                print(\"item out of bounds\",i_idx)\n",
    "                print(u,i,r)\n",
    "                return 0,0\n",
    "            err = r - np.dot(p[u_idx], q[i_idx])\n",
    "            p[u_idx] += alpha * err * q[i_idx]\n",
    "            q[i_idx] += alpha * err * p[u_idx]\n",
    "    print (err)\n",
    "    return (list(p),list(q))\n",
    "\n",
    "def get_uir(data):\n",
    "    info = []\n",
    "    for i in range(len(data['userId'])):\n",
    "        u = data['userId'].iloc[i]\n",
    "        m = data['movieId'].iloc[i]\n",
    "        r = data['rating'].iloc[i]\n",
    "        info.append((u,m,r))\n",
    "    return info\n",
    "\n",
    "\n",
    "# def estimate(p,q,user,item)\n",
    "#     return\n",
    "\n",
    "\n",
    "\n",
    "def training_surpriselike(n_ratings, latent_factors, n_iterations):\n",
    "    import numpy as np\n",
    "    import pandas as pd\n",
    "    # from time import clock\n",
    "    '''\n",
    "    Read data from \"ratings.csv\" and use SVD or NMF to factorize the users-items\n",
    "    matriz for recommendations\n",
    "    '''\n",
    "\n",
    "    # read data from file to a table\n",
    "    data = pd.read_csv(\"ratings.csv\")\n",
    "    data = data.iloc[0 : n_ratings]\n",
    "    data = data[['userId', 'movieId', 'rating']]\n",
    "    info = get_uir(data)\n",
    "    R_df = data.pivot(index='userId', columns ='movieId', values='rating').fillna(0) #NEW\n",
    "    test_df = 0\n",
    "\n",
    "    p, q = SGD(data, R_df, info, latent_factors, n_iterations)\n",
    "\n",
    "    train_df = 0\n",
    "    model = 0\n",
    "    H = 0\n",
    "    U = 0\n",
    "    return data, R_df, test_df, p, q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-0.8154500061370884\n",
      "Elapsed time for movie recommendation training: 8.44 secs\n",
      "users: 91\n",
      "movies: 2889\n"
     ]
    }
   ],
   "source": [
    "n_ratings = 10000\n",
    "latent_factors = 5\n",
    "n_iterations = 10\n",
    "training_start = time.time()\n",
    "#data, model, movies, R_df, test, users = online_nmf.training(n_ratings, latent_factors, n_iterations)\n",
    "data, R_df, test_df, p, q = training_surpriselike(n_ratings, latent_factors, n_iterations)\n",
    "training_end = time.time()\n",
    "print(\"Elapsed time for movie recommendation training: %.2f secs\" % (training_end-training_start))\n",
    "print(\"users:\",R_df.shape[0])\n",
    "print(\"movies:\",R_df.shape[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "selecting 274 users\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.338055086531968"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def get_RMSE():\n",
    "    from numpy.random import choice\n",
    "    from sklearn.metrics import mean_squared_error as mse\n",
    "\n",
    "    N_test = int(users.shape[0]*0.2)\n",
    "    print (\"selecting\",N_test,\"users\")\n",
    "    RMSE = 0.\n",
    "    RMSEII = 0.\n",
    "    numbers = choice(users.shape[0], size=N_test)\n",
    "    reals = []\n",
    "    estimates = []\n",
    "    for user_idx in numbers:\n",
    "        \n",
    "        real_user = R_df.iloc[user_idx]\n",
    "        real_user = real_user.values.reshape(-1,real_user.shape[0])[0]\n",
    "        reals.append(real_user)\n",
    "        \n",
    "        est_user = users[user_idx]\n",
    "        est_user = est_user.reshape(-1,est_user.shape[0])\n",
    "        est_user = np.rint(model.inverse_transform(est_user))[0]\n",
    "        estimates.append(est_user)\n",
    "        \n",
    "        # # this is the same that sklearn does. Just in case\n",
    "        #aux = 0.\n",
    "        #for j in range(len(real_user)):\n",
    "        #    aux += (real_user[j]-est_user[j])*(real_user[j]-est_user[j])\n",
    "        #aux = aux/float(len(real_user))\n",
    "        #RMSEII += aux\n",
    "        \n",
    "    RMSE = np.sqrt( mse(reals,estimates) )\n",
    "    #RMSEII = np.sqrt( RMSEII/float(len(numbers)) )\n",
    "    \n",
    "    return RMSE#, RMSEII\n",
    "get_RMSE()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_set(R_df):\n",
    "    import pandas as pd\n",
    "    from numpy.random import choice\n",
    "\n",
    "    def contains_duplicates(X):\n",
    "        return len(np.unique(X)) != len(X)\n",
    "\n",
    "    train_df = R_df.copy(deep=True)\n",
    "#    test_df = pd.DataFrame({'userId' : [], 'movieId' : [], 'rating' : []})\n",
    "\n",
    "#    print len(R_df.columns)\n",
    "    test_movies = choice(R_df.columns, size=int(R_df.shape[1]*0.2), replace=False)\n",
    "\n",
    "#    test_movies = choice(R_df.columns, size=1000, replace=False)\n",
    "    if (contains_duplicates(test_movies)):\n",
    "        print(\"DUPS\")\n",
    "        return\n",
    "\n",
    "    print(\"using\",len(test_movies),\"movies as test\")\n",
    "\n",
    "    test_ratings = []\n",
    "    test_users = []\n",
    "\n",
    "    skipped = 0\n",
    "    for tm in test_movies:\n",
    "        aux = R_df[tm].nonzero()[0]\n",
    "        if aux.size == 0:\n",
    "            skipped += 1\n",
    "            continue\n",
    "        fm = aux[0] # Movie\n",
    "#        test_users.append(R_df.index[fm]) # user (got from its index, just in case)\n",
    "        test_users.append(R_df.index.get_loc(R_df.index[fm]))\n",
    "        test_ratings.append( R_df[tm][R_df.index[fm]] ) # column = Movie, row = index of first nonzero rating for Movie\n",
    "        train_df[tm].iloc[R_df.index[fm]] = 0\n",
    "\n",
    "    # data_df has some erased entries\n",
    "    # R_df is the same as before\n",
    "    if skipped != 0:\n",
    "        print(\"(\",skipped,\" skipped)\")\n",
    "    test_movies = [ R_df.columns.get_loc(k) for k in test_movies]\n",
    "\n",
    "\n",
    "    #test_df.reset_index(inplace=True)\n",
    "    #train_df.reset_index(inplace=True)\n",
    "    #test_df.drop('index',axis=1,inplace=True)\n",
    "    #train_df.drop('index',axis=1,inplace=True)\n",
    "\n",
    "    return train_df,test_movies, test_users, test_ratings\n",
    "# # beware of the return values !!!! split_set(R_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def get_RMSEII(users,movies,R_df,test_users,test_movies,test_ratings,model):\n",
    "    import numpy as np\n",
    "    #print users[list(test_users)[10]]\n",
    "    #print(users[347]) just to check\n",
    "    \n",
    "    U = np.asarray(users)\n",
    "    M = np.transpose(movies)\n",
    "    test_users = np.array(test_users)\n",
    "    test_movies = np.array(test_movies)\n",
    "    \n",
    "    estimates = []\n",
    "    reals = []\n",
    "    \n",
    "    RMSEII = 0.\n",
    "    for idx in range(len(test_users)):\n",
    "        tusr = U[test_users[idx]]\n",
    "        tusr = tusr.reshape(-1,tusr.shape[0])\n",
    "        #tr_usr = model.inverse_transform(tusr)\n",
    "\n",
    "        tmov = M[test_movies[idx]]\n",
    "        tmov = tmov.reshape(-1,tmov.shape[0])\n",
    "\n",
    "#        print(tusr[0])\n",
    "#        print(tmov[0])\n",
    "#        print(np.dot(tmov[0],tusr[0]))\n",
    "\n",
    "        realthing = test_ratings[idx]#R_df.iloc[test_movies[idx]].iloc[test_users[idx]]\n",
    "        rat = np.dot(tmov[0],tusr[0])\n",
    "        RMSEII += (rat-realthing)*(rat-realthing)\n",
    "    RMSEII = np.sqrt(RMSEII/float(len(test_users)))\n",
    "    return RMSEII\n",
    "#train_df,test_movies, test_users, test_ratings = split_set(R_df)\n",
    "#get_RMSEII(users,movies,R_df,test_users,test_movies,test_ratings,model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "using 2030 movies as test\n",
      "using 2030 movies as test\n",
      "using 2030 movies as test\n",
      "using 2030 movies as test\n",
      "using 2030 movies as test\n",
      "using 2030 movies as test\n",
      "using 2030 movies as test\n",
      "using 2030 movies as test\n",
      "using 2030 movies as test\n",
      "using 2030 movies as test\n",
      "MEAN:  3.2735227300443306\n",
      "selecting 274 users\n",
      "On train set: 0.3982622532428444\n"
     ]
    }
   ],
   "source": [
    "N_tests = 10\n",
    "mean = 0.\n",
    "for i in range(N_tests):\n",
    "    train_df,test_movies, test_users, test_ratings = split_set(R_df)\n",
    "    a = get_RMSEII(users,movies,R_df,test_users,test_movies,test_ratings,model)\n",
    "    #print(a)\n",
    "    mean += a\n",
    "print(\"MEAN: \",mean/float(N_tests))\n",
    "print(\"On train set:\",get_RMSE())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "@webio": {
   "lastCommId": "6cfbd45c27334d93bf23f50211c55cd8",
   "lastKernelId": "a2771b76-54e7-44a7-8681-c541fec12807"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
