{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'lightfm'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-b3bf6b886652>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;31m#import lightfm\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mlightfm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdatasets\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mfetch_movielens\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mmovielens\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfetch_movielens\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'lightfm'"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "#import lightfm\n",
    "from lightfm.datasets import fetch_movielens\n",
    "\n",
    "movielens = fetch_movielens()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'scipy.sparse.coo.coo_matrix'>\n"
     ]
    }
   ],
   "source": [
    "train = movielens['train']\n",
    "test = movielens['test']\n",
    "print (type(train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision: train 0.59, test 0.10.\n",
      "AUC: train 0.89, test 0.86.\n"
     ]
    }
   ],
   "source": [
    "from lightfm import LightFM\n",
    "from lightfm.evaluation import precision_at_k\n",
    "from lightfm.evaluation import auc_score\n",
    "\n",
    "model = LightFM(learning_rate=0.05, loss='bpr')\n",
    "model.fit(train, epochs=10)\n",
    "\n",
    "train_precision = precision_at_k(model, train, k=10).mean()\n",
    "test_precision = precision_at_k(model, test, k=10).mean()\n",
    "\n",
    "train_auc = auc_score(model, train).mean()\n",
    "test_auc = auc_score(model, test).mean()\n",
    "\n",
    "print('Precision: train %.2f, test %.2f.' % (train_precision, test_precision))\n",
    "print('AUC: train %.2f, test %.2f.' % (train_auc, test_auc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision: train 0.60, test 0.11.\n",
      "AUC: train 0.93, test 0.90.\n"
     ]
    }
   ],
   "source": [
    "from lightfm import LightFM\n",
    "from lightfm.evaluation import precision_at_k\n",
    "from lightfm.evaluation import auc_score\n",
    "\n",
    "model = LightFM(learning_rate=0.05, loss='warp')\n",
    "\n",
    "model.fit_partial(train, epochs=10)\n",
    "\n",
    "train_precision = precision_at_k(model, train, k=10).mean()\n",
    "test_precision = precision_at_k(model, test, k=10).mean()\n",
    "\n",
    "train_auc = auc_score(model, train).mean()\n",
    "test_auc = auc_score(model, test).mean()\n",
    "\n",
    "print('Precision: train %.2f, test %.2f.' % (train_precision, test_precision))\n",
    "print('AUC: train %.2f, test %.2f.' % (train_auc, test_auc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-1.65489483]\n"
     ]
    }
   ],
   "source": [
    "#print(test)\n",
    "user = np.array([1])\n",
    "movie = np.array([10])\n",
    "a = model.predict(user,movie)\n",
    "print(a)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# copy-paste from Raval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision: train 0.52, test 0.08.\n",
      "AUC: train 0.95, test 0.92.\n",
      "['Toy Story (1995)' 'GoldenEye (1995)' 'Four Rooms (1995)' ...\n",
      " 'Sliding Doors (1998)' 'You So Crazy (1994)'\n",
      " 'Scream of Stone (Schrei aus Stein) (1991)']\n",
      "(943, 1682)\n",
      "User: 1\n",
      "Rated:\n",
      "       Toy Story (1995)\n",
      "       Postino, Il (1994)\n",
      "       Birdcage, The (1996)\n",
      "       Fargo (1996)\n",
      "       Truth About Cats & Dogs, The (1996)\n",
      "Recommended:\n",
      "       English Patient, The (1996)\n",
      "       L.A. Confidential (1997)\n",
      "       Titanic (1997)\n",
      "       Contact (1997)\n",
      "       Air Force One (1997)\n",
      "['Toy Story (1995)' 'GoldenEye (1995)' 'Four Rooms (1995)' ...\n",
      " 'Sliding Doors (1998)' 'You So Crazy (1994)'\n",
      " 'Scream of Stone (Schrei aus Stein) (1991)']\n",
      "(943, 1682)\n",
      "User: 2\n",
      "Rated:\n",
      "       Return of the Jedi (1983)\n",
      "       Event Horizon (1997)\n",
      "       Schindler's List (1993)\n",
      "       Paradise Lost: The Child Murders at Robin Hood Hills (1996)\n",
      "       Mother (1996)\n",
      "Recommended:\n",
      "       L.A. Confidential (1997)\n",
      "       Contact (1997)\n",
      "       Scream (1996)\n",
      "       Titanic (1997)\n",
      "       Chasing Amy (1997)\n",
      "['Toy Story (1995)' 'GoldenEye (1995)' 'Four Rooms (1995)' ...\n",
      " 'Sliding Doors (1998)' 'You So Crazy (1994)'\n",
      " 'Scream of Stone (Schrei aus Stein) (1991)']\n",
      "(943, 1682)\n",
      "User: 3\n",
      "Rated:\n",
      "       Seven (Se7en) (1995)\n",
      "       Contact (1997)\n",
      "       Starship Troopers (1997)\n",
      "       Air Force One (1997)\n",
      "       In & Out (1997)\n",
      "Recommended:\n",
      "       Game, The (1997)\n",
      "       Scream (1996)\n",
      "       Contact (1997)\n",
      "       Air Force One (1997)\n",
      "       Devil's Advocate, The (1997)\n"
     ]
    }
   ],
   "source": [
    "# copy-paste from Raval\n",
    "from lightfm import LightFM\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from lightfm.datasets import fetch_movielens\n",
    "from lightfm.evaluation import precision_at_k\n",
    "from lightfm.evaluation import auc_score\n",
    "\n",
    "\n",
    "movielens = fetch_movielens()\n",
    "\n",
    "data = fetch_movielens(min_rating=4.)\n",
    "train = data['train']\n",
    "test = data['test']\n",
    "model = LightFM(learning_rate=0.05, loss='warp')\n",
    "model.fit(data['train'],epochs=20,num_threads=2)\n",
    "\n",
    "train_precision = precision_at_k(model, train, k=10).mean()\n",
    "test_precision = precision_at_k(model, test, k=10).mean()\n",
    "\n",
    "train_auc = auc_score(model, train).mean()\n",
    "test_auc = auc_score(model, test).mean()\n",
    "\n",
    "print('Precision: train %.2f, test %.2f.' % (train_precision, test_precision))\n",
    "print('AUC: train %.2f, test %.2f.' % (train_auc, test_auc))\n",
    "\n",
    "\n",
    "\n",
    "def recommendation(model, data, user_ids):\n",
    "    n_users, n_items = data['train'].shape\n",
    "    \n",
    "    for user_id in user_ids:\n",
    "        known_positives = data['item_labels'][data['train'].tocsr()[user_id].indices]\n",
    "        print(data['item_labels'])\n",
    "        print(data['train'].shape)\n",
    "        scores = model.predict(user_id, np.asarray(range(n_items)))\n",
    "        top_items = data['item_labels'][np.argsort(-scores)]\n",
    "        \n",
    "        print(\"User:\",user_id)\n",
    "        print(\"Rated:\")\n",
    "        for i in known_positives[:5]:\n",
    "            print(\"      \",i)\n",
    "        print(\"Recommended:\")\n",
    "        for i in top_items[:5]:\n",
    "            print(\"      \",i)\n",
    "    return\n",
    "\n",
    "\n",
    "recommendation(model, data, [1,2,3])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Custom dataset loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "175\n",
      "Num users: 3374, num_items 12277.\n",
      "['Toy Story (1995)' 'Jumanji (1995)' 'Grumpier Old Men (1995)' ...\n",
      " 'The Pirates (2014)' 'Rentun Ruusu (2001)' 'Innocence (2014)']\n"
     ]
    }
   ],
   "source": [
    "def load_data():\n",
    "    import numpy as np\n",
    "    import pandas as pd\n",
    "    from lightfm.datasets import fetch_movielens\n",
    "    from lightfm.data import Dataset\n",
    "\n",
    "    n_ratings = 500000\n",
    "\n",
    "    # Load the file into a dataframe\n",
    "    #table = pd.read_table(\"~/lightfm_data/movielens100k/ml-100k/u.data\",names=['userId','movieId','rating','timestamp'])\n",
    "    table = pd.read_csv(\"ratings.csv\")\n",
    "    #### TESTING ITEMS LABELING\n",
    "    file = pd.read_csv(\"movies.csv\")\n",
    "    file['title'].str.split()\n",
    "    user1movies = []\n",
    "    for i in range(len(table['userId'])):\n",
    "        if table['userId'][i] == 2:\n",
    "            break\n",
    "        else:\n",
    "            user = file[file['movieId']==table['movieId'][i]]\n",
    "            #print(user['title'].values[0].strip())\n",
    "            user1movies.append(user['title'].values[0].strip())\n",
    "#            movie = user['title'].split(',')[0]\n",
    "    #### END ITEMS LABELING TEST\n",
    "    print(len((table[ table['userId']==1 ])['userId']))##################################################################################    \n",
    "    table = table[['userId','movieId']].iloc[:n_ratings]\n",
    "    table = table.astype(np.int32)    \n",
    "\n",
    "    # Perform the mapping between users and movies needed for creating interaction matrices\n",
    "    data = Dataset()\n",
    "    data.fit(table['userId'], table['movieId'])\n",
    "\n",
    "    # Get some useful numbers\n",
    "    num_users, num_items = data.interactions_shape()\n",
    "    print('Num users: {}, num_items {}.'.format(num_users, num_items))\n",
    "\n",
    "    # Creating interaction matrices\n",
    "    tuples = [tuple(x) for x in table[['userId','movieId']].values]\n",
    "    (interactions, weights) = data.build_interactions(tuples)\n",
    "\n",
    "    return interactions,user1movies\n",
    "\n",
    "\n",
    "#i, u1m= load_data()\n",
    "\n",
    "def label_items():\n",
    "    import pandas as pd\n",
    "    import numpy as np\n",
    "    \n",
    "    file = pd.read_csv(\"movies.csv\")\n",
    "    #file['title'] = file['title'].apply(lambda x: x.split(',')[0])\n",
    "    file = np.asarray(file['title'].tolist())\n",
    "    return file\n",
    "\n",
    "\n",
    "def get_metrics(interactions,u1m):\n",
    "    from lightfm.cross_validation import random_train_test_split\n",
    "    from lightfm import LightFM\n",
    "    from lightfm.evaluation import precision_at_k\n",
    "    from lightfm.evaluation import auc_score\n",
    "\n",
    "    (train_set, test_set) = random_train_test_split(interactions, test_percentage=0.2, random_state=None)\n",
    "    ##########  TESTING ITEMS LABELING\n",
    "    movie_labels = label_items()\n",
    "    print(movie_labels)\n",
    "    return\n",
    "    user = 0\n",
    "    #print(movie_labels[train_set.tocsr()[user].indices])\n",
    "    #labels = ''.join(list(movie_labels[train_set.tocsr()[user].indices]))\n",
    "    labels = movie_labels[train_set.tocsr()[user].indices]\n",
    "    #strlist = ''.join(labels)\n",
    "    \n",
    "    print(len(u1m))\n",
    "    print(len(labels))\n",
    "    print(labels)\n",
    "#    for thing in u1m:\n",
    "#        if not thing in labels:\n",
    "#            print(\"BULLSHIT\",thing)\n",
    "#            #return\n",
    "#    print(\"CLEAN!\")\n",
    "    return\n",
    "    ##########  ENDING ITEMS LABELING TEST\n",
    "    model = LightFM(loss='warp')\n",
    "    model.fit(train_set, epochs=20, num_threads=2)\n",
    "\n",
    "    train_precision = precision_at_k(model, train_set, k=20).mean()\n",
    "    test_precision = precision_at_k(model, test_set, k=20).mean()\n",
    "\n",
    "    train_auc = auc_score(model, train_set).mean()\n",
    "    test_auc = auc_score(model, test_set).mean()\n",
    "\n",
    "\n",
    "    print('Precision: train %.2f, test %.2f.' % (train_precision, test_precision))\n",
    "    print('AUC: train %.2f, test %.2f.' % (train_auc, test_auc))\n",
    "    return\n",
    "get_metrics(i,u1m)\n",
    "\n",
    "def recommendation(model, data, user_ids):\n",
    "    n_users, n_items = data['train'].shape\n",
    "    \n",
    "    for user_id in user_ids:\n",
    "        known_positives = data['item_labels'][data['train'].tocsr()[user_id].indices]\n",
    "        # hay que construir otem_labels como en el fetch_movielens\n",
    "        # hecho en la func \"label_items\"\n",
    "        \n",
    "        \n",
    "        scores = model.predict(user_id, np.asarray(range(n_items)))\n",
    "        top_items = data['item_labels'][np.argsort(-scores)]\n",
    "        \n",
    "        print(\"User:\",user_id)\n",
    "        print(\"Rated:\")\n",
    "        for i in known_positives[:5]:\n",
    "            print(\"      \",i)\n",
    "        print(\"Recommended:\")\n",
    "        for i in top_items[:5]:\n",
    "            print(\"      \",i)\n",
    "    return\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num users: 3374, num_items 12277.\n",
      "Precision: train 0.43, test 0.10.\n",
      "AUC: train 0.97, test 0.95.\n"
     ]
    }
   ],
   "source": [
    "ints = load_data()\n",
    "get_metrics(ints)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df1 = pd.read_csv(\"ratings.csv\")\n",
    "df2 = pd.read_csv(\"movies.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "columns overlap but no suffix specified: Index(['movieId'], dtype='object')",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-45-ea93979c14bb>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mdf3\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf1\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf2\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mon\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'movieId'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/anaconda3/envs/new_reomender/lib/python3.7/site-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36mjoin\u001b[0;34m(self, other, on, how, lsuffix, rsuffix, sort)\u001b[0m\n\u001b[1;32m   6334\u001b[0m         \u001b[0;31m# For SparseDataFrame's benefit\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   6335\u001b[0m         return self._join_compat(other, on=on, how=how, lsuffix=lsuffix,\n\u001b[0;32m-> 6336\u001b[0;31m                                  rsuffix=rsuffix, sort=sort)\n\u001b[0m\u001b[1;32m   6337\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   6338\u001b[0m     def _join_compat(self, other, on=None, how='left', lsuffix='', rsuffix='',\n",
      "\u001b[0;32m~/anaconda3/envs/new_reomender/lib/python3.7/site-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36m_join_compat\u001b[0;34m(self, other, on, how, lsuffix, rsuffix, sort)\u001b[0m\n\u001b[1;32m   6349\u001b[0m             return merge(self, other, left_on=on, how=how,\n\u001b[1;32m   6350\u001b[0m                          \u001b[0mleft_index\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mon\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mright_index\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 6351\u001b[0;31m                          suffixes=(lsuffix, rsuffix), sort=sort)\n\u001b[0m\u001b[1;32m   6352\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   6353\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mon\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/new_reomender/lib/python3.7/site-packages/pandas/core/reshape/merge.py\u001b[0m in \u001b[0;36mmerge\u001b[0;34m(left, right, how, on, left_on, right_on, left_index, right_index, sort, suffixes, copy, indicator, validate)\u001b[0m\n\u001b[1;32m     60\u001b[0m                          \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindicator\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mindicator\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     61\u001b[0m                          validate=validate)\n\u001b[0;32m---> 62\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mop\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_result\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     63\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     64\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/new_reomender/lib/python3.7/site-packages/pandas/core/reshape/merge.py\u001b[0m in \u001b[0;36mget_result\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    572\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    573\u001b[0m         llabels, rlabels = items_overlap_with_suffix(ldata.items, lsuf,\n\u001b[0;32m--> 574\u001b[0;31m                                                      rdata.items, rsuf)\n\u001b[0m\u001b[1;32m    575\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    576\u001b[0m         \u001b[0mlindexers\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mleft_indexer\u001b[0m\u001b[0;34m}\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mleft_indexer\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/new_reomender/lib/python3.7/site-packages/pandas/core/internals.py\u001b[0m in \u001b[0;36mitems_overlap_with_suffix\u001b[0;34m(left, lsuffix, right, rsuffix)\u001b[0m\n\u001b[1;32m   5242\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mlsuffix\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mrsuffix\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5243\u001b[0m             raise ValueError('columns overlap but no suffix specified: '\n\u001b[0;32m-> 5244\u001b[0;31m                              '{rename}'.format(rename=to_rename))\n\u001b[0m\u001b[1;32m   5245\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5246\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0mlrenamer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: columns overlap but no suffix specified: Index(['movieId'], dtype='object')"
     ]
    }
   ],
   "source": [
    "df3 = df1.join(df2,on='movieId')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
